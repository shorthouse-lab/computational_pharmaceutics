{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66ac96e",
   "metadata": {},
   "source": [
    "# PHAY0076: Computational Pharmaceutics — Coursework 1 (2026)\n",
    "\n",
    "## Tablet formulation analysis: data cleaning → EDA → statistics → unsupervised learning → supervised learning\n",
    "\n",
    "**IMPORTANT**\n",
    "- Work individually.\n",
    "- Save your notebook with your **examination number** at the start of the filename (e.g., `12345678_PHAY0076_Coursework1.ipynb`).\n",
    "- Export an **HTML** version: `File → Save and Export Notebook As… → HTML`.\n",
    "- Upload the the `.html` to moodle.\n",
    "\n",
    "\n",
    "- Feel free to alter the notebook - adding in extra cells and breaking up your code into different sections.\n",
    "\n",
    "---\n",
    "\n",
    "## Context\n",
    "\n",
    "A pharmaceutical company is developing an **immediate‑release oral tablet** containing a poorly soluble API.  \n",
    "You have been given a screening dataset of ~120 formulations with measured outcomes. Your job is to:\n",
    "\n",
    "1. Clean and validate the dataset (quality checks)\n",
    "2. Explore the data using plots and descriptive statistics\n",
    "3. Use statistical tests to support (or refute) observed patterns\n",
    "4. Use unsupervised learning to identify structure in formulation space\n",
    "5. Train a simple predictive model and evaluate performance\n",
    "6. Summarise findings and suggest next experimental directions\n",
    "\n",
    "This is a simulation of a real task a computationally competent formulation scientist might be asked to do in an industrial or academic lab.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The data are provided as a .csv file:\n",
    "\n",
    "`tablet_formulation_screen_2026.csv`\n",
    "\n",
    "Place the file in the **same folder** as this notebook before running.\n",
    "\n",
    "### Expected columns\n",
    "\n",
    "**Inputs (formulation / process)**\n",
    "- `API_pct`\n",
    "- `Filler_pct`\n",
    "- `Binder_pct`\n",
    "- `Disintegrant_pct`\n",
    "- `Lubricant_pct`\n",
    "- `Polymer` (categorical)\n",
    "- `Compression_kN`\n",
    "- `Coating` (`Yes`/`No`)\n",
    "\n",
    "**Outputs (measurements)**\n",
    "- `Diss_30min`\n",
    "- `Stability_6mo`\n",
    "- `Bioavail_AUC`\n",
    "\n",
    "### API group definition\n",
    "\n",
    "As part of step 1 - you will be asked to create a categorical variable `API_group` from `API_pct`:\n",
    "\n",
    "- **Low:** `API_pct ≤ 15`\n",
    "- **Medium:** `15 < API_pct ≤ 30`\n",
    "- **High:** `API_pct > 30`\n",
    "\n",
    "---\n",
    "\n",
    "## Marking (100%)\n",
    "\n",
    "- Section 1: Data loading & cleaning — **15%**\n",
    "- Section 2: Visualisation & EDA — **20%**\n",
    "- Section 3: Statistical tests — **20%**\n",
    "- Section 4: Unsupervised learning — **15%**\n",
    "- Section 5: Supervised learning — **20%**\n",
    "- Section 6: Summary & recommendations — **10%**\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Can can double click on any cell to edit it - including the markdown cells.\n",
    "- You are **not** expected to tune models extensively. You will not be scored on the accuracy of your models - just on implementation and interpretation.\n",
    "- You may use any reasonable Python approach. Use of `pandas`, `scipy`, `seaborn`, and `scikit-learn` is recommended but not required.\n",
    "- Where the coursework asks you to justify choices, a short explanation (2–4 sentences) is sufficient.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124a6b2-37f9-4ef5-9800-84feb947196e",
   "metadata": {},
   "source": [
    "Insert your examination number here:\n",
    "\n",
    "**Exam number:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed216a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Setup (some initial libraries - you will need to load more for downstream tasks but this can get you started)\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## For loading the file in colab - use the below command:\n",
    "# data = pd.read_csv(\"https://raw.githubusercontent.com/shorthouse-lab/computational_pharmaceutics/refs/heads/main/Workshop5_coursework1/2026/tablet_formulation_screen_2026.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b952f25",
   "metadata": {},
   "source": [
    "# Section 1 — Data loading and cleaning (15%)\n",
    "\n",
    "## Tasks:\n",
    "\n",
    "1. Load the dataset from `tablet_formulation_screen_2026.csv` into a dataframe `df`.\n",
    "2. Inspect the dataframe structure and contents:\n",
    "   - `head()`, `shape`, `info()`, `describe()`\n",
    "3. Create the new column `API_group` as defined:\n",
    "\n",
    "- **Low:** `API_pct ≤ 15`\n",
    "- **Medium:** `15 < API_pct ≤ 30`\n",
    "- **High:** `API_pct > 30`\n",
    "\n",
    "4. Perform basic data quality checks:\n",
    "   - missing values (per column)\n",
    "   - duplicate rows\n",
    "   - impossible / suspicious values (e.g. negative percentages)\n",
    "   - whether the composition columns approximately sum to 100% (optional but encouraged)\n",
    "5. I recommend you create a cleaned dataframe `df_clean` for use in further down analysis.\n",
    "\n",
    "## Questions (write your answers in Markdown)\n",
    "\n",
    "**Q1 (5%)** Are there missing values? If yes, how did you handle them and why?  \n",
    "*(Hint: consider dataset size and whether missingness might bias results.)*\n",
    "\n",
    "**Q2 (10%)** From summary statistics (mean, standard deviation, and range), make **two observations about the dataset** focusing on data properties (e.g., variability, spread, outliers, constraints).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4158b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Section 1 goes here\n",
    "\n",
    "# 1) Load data into a dataframe\n",
    "\n",
    "# 2) Inspect data\n",
    "\n",
    "# 3) Create API_group\n",
    "\n",
    "# 4) Data quality checks\n",
    "\n",
    "# 5) Create df_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c340cf-0175-43b0-a610-c0c4116b106a",
   "metadata": {},
   "source": [
    "You can write your answers to the questions in a markdown cell like this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e9d33",
   "metadata": {},
   "source": [
    "# Section 2 — Visualisation and Exploratory Data Analysis (20%)\n",
    "\n",
    "## Tasks\n",
    "\n",
    "Using your cleaned dataframe (`df_clean`):\n",
    "\n",
    "1. Plot distributions (histogram or KDE) for:\n",
    "   - `Diss_30min`\n",
    "   - `Stability_6mo`\n",
    "   - `Bioavail_AUC`\n",
    "\n",
    "2. Create scatter plots (include a fitted trend line if you wish):\n",
    "   - `API_pct` vs `Diss_30min`\n",
    "   - `Compression_kN` vs `Diss_30min`\n",
    "   - `Binder_pct` vs `Stability_6mo`\n",
    "   - `Diss_30min` vs `Bioavail_AUC`\n",
    "\n",
    "3. Create box plots:\n",
    "   - `Stability_6mo` grouped by `API_group`\n",
    "   - `Diss_30min` grouped by `Polymer`\n",
    "\n",
    "4. Create a correlation heatmap for numeric columns.\n",
    "\n",
    "## Questions\n",
    "\n",
    "**Q3 (10%)** What do the distributions suggest (e.g., skew, outliers, multimodality)? What does this imply for later statistical analysis?  \n",
    "*(Example: whether parametric tests might be reasonable.)*\n",
    "\n",
    "**Q4 (10%)** Identify **two relationships** between **inputs and outputs** supported by your plots (direction + brief description).  \n",
    "*(Example structure: “As X increases, Y tends to increase/decrease, supported by plot Z”.)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd2d06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Section 2 goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2225da-6f91-43d9-9098-221a0660bca1",
   "metadata": {},
   "source": [
    "You can write your answers to the questions in a markdown cell like this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62e174",
   "metadata": {},
   "source": [
    "# Section 3 — Statistical tests (20%)\n",
    "\n",
    "## Tasks\n",
    "\n",
    "Using `df_clean`:\n",
    "\n",
    "1. Perform a **one-way ANOVA** to test whether `Stability_6mo` differs across `API_group` (Low/Medium/High).\n",
    "2. If your ANOVA is significant, perform a **post-hoc** comparison between groups (any reasonable approach is acceptable).\n",
    "3. Calculate correlation coefficients and **p-values** for:\n",
    "   - `Binder_pct` vs `Stability_6mo`\n",
    "   - `API_pct` vs `Diss_30min`\n",
    "   - `Diss_30min` vs `Bioavail_AUC`\n",
    "\n",
    "## Questions\n",
    "\n",
    "**Q5 (10%)** Is there evidence that stability differs between API groups? Report the test statistic and p-value and interpret in plain language.\n",
    "\n",
    "**Q6 (10%)** Which correlations are statistically significant? Briefly comment on which are likely to be practically meaningful.  \n",
    "Also state whether you used Pearson or Spearman correlation for each test and why.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Section 3 goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c51d7-1491-4627-aca9-bf37e508c340",
   "metadata": {},
   "source": [
    "You can write your answers to the questions in a markdown cell like this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92682e",
   "metadata": {},
   "source": [
    "# Section 4 — Unsupervised learning (15%)\n",
    "\n",
    "## Tasks\n",
    "\n",
    "Using `df_clean`:\n",
    "\n",
    "1. Build an input feature table `X` using:\n",
    "   - Numeric inputs: `API_pct`, `Filler_pct`, `Binder_pct`, `Disintegrant_pct`, `Lubricant_pct`, `Compression_kN`\n",
    "   - Categorical inputs: `Polymer`, `Coating`\n",
    "\n",
    "\n",
    "2. Preprocess:\n",
    "   - standardise numeric columns and remove non-numeric columns\n",
    "\n",
    "\n",
    "3. Perform **PCA** and plot **PC1 vs PC2**:\n",
    "   - colour points by `API_group`\n",
    "\n",
    "4. Perform **KMeans clustering** (choose a reasonable k) and plot clusters on the PCA scatter plot.\n",
    "\n",
    "## Questions\n",
    "\n",
    "**Q7 (10%)** What does PCA show? What do PC1 and PC2 represent in terms of formulation/process variables?  \n",
    "*(Hint - you can PCA loadings to support your interpretation, or plot numeric values on the PCA to see the trends.)*\n",
    "\n",
    "**Q8 (5%)** Do your clusters align with `API_group` or other variables (Polymer/Coating)? What might that suggest about formulation “families”?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded8c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Section 4 goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f269604-6b5e-46a7-a9fe-f1c9f810b292",
   "metadata": {},
   "source": [
    "You can write your answers to the questions in a markdown cell like this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e22c04",
   "metadata": {},
   "source": [
    "# Section 5 — Supervised learning (20%)\n",
    "\n",
    "Build a simple predictive model to predict dissolution (`Diss_30min`) from formulation inputs.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Define:\n",
    "   - `X` = inputs (same as Section 4)\n",
    "   - `y` = `Diss_30min`\n",
    "\n",
    "2. Split data into training and test sets (e.g., 80/20).\n",
    "\n",
    "3. Train two models:\n",
    "   - Linear regression\n",
    "   - Random forest regression (or another model of your choice)\n",
    "\n",
    "4. Evaluate test performance using:\n",
    "   - MAE\n",
    "   - RMSE\n",
    "   - Comparing the scores to just predicting the mean of the dataset\n",
    "\n",
    "6. Plot **predicted vs observed** for the test set.\n",
    "\n",
    "## Questions\n",
    "\n",
    "**Q9 (10%)** How well can dissolution be predicted from the available inputs? Does your model beat just predicting the mean of the dataset? Discuss limitations.\n",
    "\n",
    "**Q10 (10%)** Which features appear important (if your model provides feature importance or coefficients)? Do they make formulation sense?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96190919-8e80-4d81-83f4-82e5b744ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Section 5 goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c407e8-f40f-4ee0-b590-023529e4d0aa",
   "metadata": {},
   "source": [
    "You can write your answers to the questions in a markdown cell like this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d2d22-90e9-414b-93f0-42b4ee36dbf2",
   "metadata": {},
   "source": [
    "# Your code for Section 5 goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fe648",
   "metadata": {},
   "source": [
    "# Section 6 — Summary & recommendations (10%)\n",
    "\n",
    "**Q11 (10%)** Write ~5 sentences summarising:\n",
    "\n",
    "- key EDA findings\n",
    "- key statistical results (include p-values where relevant)\n",
    "- PCA/clustering findings\n",
    "- model performance (include at least one metric)\n",
    "- two practical recommendations for formulation development\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59ca9e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Academic integrity reminder\n",
    "\n",
    "Use of AI tools is recommended for debugging/syntax, but make sure you check you understand code you are running before submitting. Your analysis and interpretations should be (at least mostly!) your own.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ac37d-0875-4bcd-be53-eb2e7d5b5667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
